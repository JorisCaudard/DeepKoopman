import streamlit as st

st.set_page_config(
    page_title="Network Architecture",
    page_icon="üß†",
    layout= 'wide'
)

st.title("Network architecture")

tab1, tab2 = st.tabs(["Structure th√©orique", "Aper√ßu du code"])

with tab1:
    st.header("Architecture de l'AutoEncoder DeepKoopman", divider= True)
    st.image("https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig1_HTML.png?as=webp")
    
    st.markdown(r'''L'architecture propos√©e dans le cadre de l'apprentissage de l'op√©rateur de Koopman se base sur une structure classique d'Auto-encoder. 
                L'objectif √©tant d'identifier un op√©rateur lin√©aire dans un espace d'√©tat latent, l'espace latent de l'auto-encoder prend la forme d'une matrice, qu'on assimile dans l'impl√©mentation python √† une couche Lin√©aire sans biais.''')
    
    st.markdown(r'''Le r√©seau est bas√© sur un autoencodeur qui est capable d'identifier les coordonn√©es intrins√®ques 
    $y = \varphi (x)$ et de d√©coder ces coordonn√©es pour r√©cup√©rer $x = \varphi^{-1}(y)$.''')
    
    st.image("https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41467-018-07210-0/MediaObjects/41467_2018_7210_Fig2_HTML.png?as=webp")
    
    st.markdown(r'''L'ajout d'un r√©seau auxiliaire permet d'identifier le spectre des valeurs propres continues de l'op√©rateur $K$. Cela facilite 
    une r√©duction de dimension agressive dans l'auto-encodeur, √©vitant ainsi le besoin de plus hautes harmoniques de la fr√©quence 
    qui sont g√©n√©r√©es par la non-lin√©arit√©.''')

with tab2:
    st.header("Impl√©mentation en Python", divider= True)

    st.markdown(r"L'impl√©mentation de ce r√©seau simple de Koopman a √©t√© faite en utilisant les focntionnalit√©s du module python Pytorch.")

    st.code("""class SimpleKoopmanNeuralNetwork(nn.Module):
    \"""Classe repr√©sentant un r√©seau de neurones simple de Koopman.
    Ce r√©seau de neurones prend un √©tat en entr√©e et pr√©dit la trajectoire correspondante.

    Attributes:
        params (dict): Param√®tres relatifs √† la structure du r√©seau.
        Encoder (nn.Sequential): Encoder du r√©seau. 
        Decoder (nn.Sequential): Decoder du r√©seau.
        K (nn.Linear): Matrice de l'op√©rateur de Koopman, identifi√©e √† une couche nn.Linear sans biais.

    Methods:
        __init__: Initialise les param√®tres du r√©seau de neurones.
        forward: Pr√©dit une trajectoire √† partir d'un √©tat initial
    \"""

    def __init__(self, params):
        \"""Initialise le r√©seau de neurones avec la configuration sp√©cifi√©e.

        Args:
            params (dict): Un dictionnaire contenant la configuration initiale du r√©seau de neurones.
                Ce dictionnaire doit inclure les param√®tres inputSize, hiddenSize, hiddenLayer, latentSize.
        \"""
        super(SimpleKoopmanNeuralNetwork, self).__init__()
        
        self.params = params

        inputSize, hiddenSize, hiddenLayer, latentSize = self.params['inputSize'], self.params['hiddenSize'], self.params['hiddenLayer'], self.params['latentSize']

        #Input layer of Encoder
        encoderLayers = [nn.Linear(inputSize, hiddenSize), nn.ReLU()]

        ###Define Encoder Layer
        for _ in range(hiddenLayer):
            encoderLayers.append(nn.Linear(hiddenSize, hiddenSize))
            encoderLayers.append(nn.ReLU())

        #Output layer of Encoder
        encoderLayers.append(nn.Linear(hiddenSize, latentSize))

        #Creating the Encoder Network
        self.Encoder = nn.Sequential(*encoderLayers)

        #Input layer of Decoder
        decoderLayers = [nn.Linear(latentSize, hiddenSize), nn.ReLU()]

        ###Define Decoder Layer
        for _ in range(hiddenLayer):
            decoderLayers.append(nn.Linear(hiddenSize, hiddenSize))
            decoderLayers.append(nn.ReLU())

        #Output layer of Decoder
        decoderLayers.append(nn.Linear(hiddenSize, inputSize))

        #Creating the Decoder Network
        self.Decoder = nn.Sequential(*decoderLayers)

        #Simple Koopman Auto-Encoder (Without Auxiliary Network)
        self.K = nn.Linear(latentSize, latentSize, bias=False)

    def forward(self, initialInput):
        \"""Pr√©dit une trajectoire de longueur 50 √† partir d'un √©tat initial.

        Args:
            intialInput (nn.Tensor): √âtat initial, de dimension inputSize.

        Returns:
            trajectoryPrediction (list): Trajectoire pr√©dite sur 50 steps
        \"""
        #Take as input a 2 dimension tensor (initial State)

        #get the first encoded state (y1)
        encodedInitialInput = self.Encoder(initialInput)

        #First element of the latent trajectory is encoded input
        latentTrajectoryPrediction = [encodedInitialInput]

        #Alongside the trajectory, we multiply by the Koopman operator
        for _ in range(49):
            latentTrajectoryPrediction.append(self.K(latentTrajectoryPrediction[-1]))

        #Decoding the trajectory
        trajectoryPrediction = []

        for latentState in latentTrajectoryPrediction:
            trajectoryPrediction.append(self.Decoder(latentState))
        
        #We output the trajectoryPrediction
        return trajectoryPrediction""")