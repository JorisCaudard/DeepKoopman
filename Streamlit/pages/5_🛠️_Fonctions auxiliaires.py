import streamlit as st

st.set_page_config(
    page_title="Training/testing",
    page_icon="üõ†Ô∏è",
    layout= 'wide'
)

st.title("Fonctions utilitaires")

tab1, tab2 = st.tabs(["Data Loading", "Train function"])

with tab1:
    st.header("Data Loading")

    st.markdown("Les fichiers de donn√©es raw contiennent des trajectoires possibles (calcul√©es en r√©solavnt des √©quations diff√©rentielles). Il est n√©cessaire pour l'entra√Æenement du mod√®le de les transformer en Dataset (classe du module pytorch), afin de pouvoir entra√Æner les mod√®les. On cr√©e aussi un Dataloader permettant d'it√©rer sur le Dataset pour l'entra√Ænement du mod√®le.")

    st.subheader("Classe Dataset")
    st.code("""
class TrajectoryDataset(Dataset):
    \"""Cr√©ation des datasets de trajectoires √† partir des fichiers raw.

    Attributes:
        trajectoryDataset (dataframe): Dataframe √† une colonne contenant chaque trajectoire construite.

    Methods:
        __init__: Initialise les param√®tres du Dataset.
        __len__: Calcule la longueur du Dataset.
        __getitem___: Sort la i-eme trajectoire du Dataset.

    Example:
        Cr√©ation du dataset d'entra√Ænement.
        trajectoryDataset = TrajectoryDataset('Koopman Final Files/Data/DiscreteSpectrumExample_train.csv')
    \"""
    def __init__(self, filePath):
        \"""Initialise les param√®tres du Dataset.

        Args:
            filePath (str): Chemin du fichier raw de train/test.
        \"""
        
        #Load the dataset
        fullDataset = pd.read_csv(filePath, header= None)

        #Create the target from the dataset (i.e the full trajectory of 50 steps)
        trajectoryList = []

        for i in range(0, len(fullDataset), 51):
            rows = fullDataset.iloc[i:i+50]
            trajectory = [torch.tensor(tuple(row), dtype= torch.float64) for index, row in rows.iterrows()]
            trajectoryList.append(trajectory)
            

        self.trajectoryDataset = pd.DataFrame({'Trajectories': trajectoryList})

    def __len__(self):
        \"""Calcule la longueur du Dataset.

        Args:
            None.

        Returns:
            int: Nombre de trajectoires du Dataset.
        \"""
        return self.trajectoryDataset.shape[0]
    
    def __getitem__(self, index):
        \"""Sort la i-eme trajectoire du Dataset.

        Args:
            index (int): Index de la trajectoire √† extraire.

        Returns:
            list: Trajectoire du Dataset √† l'index i.
        \"""
        return self.trajectoryDataset.loc[index, 'Trajectories']
        """
    )

    st.subheader("Fonction Dataloader")

    st.code("""
    def getDataLoader(dataset, batchSize=128):
        \"""Sort la i-eme trajectoire du Dataset.

        Args:
            dataset (Dataset): Dataset √† transformer en Dataloader.
            batchsize (int, optional): Batch Size du Dataloader. Par d√©faut, 128.

        Returns:
            Dataloader: Dataloader correspondant au Dataset
        \"""
        return DataLoader(dataset, batch_size= batchSize)
            """)
    
    with tab2:
        st.header("Train loop function")

        st.markdown("Voici l'impl√©mentation de la fonction d'entra√Ænement utilis√©e ici :")

        st.code("""def pytorchTraining(koopmanModel, koopmanLoss, optimizer, epoch, dataloader):
  \"""Fonction d'entra√Ænement du mod√®le.

  Args:
    koopmanModel (SimpleKoopmanNeuralNetwork): Une instance d'un mod√®le d'auto-encoder de Koopman.
    koopmanLoss (LossFunction): Fonction de perte √† optimiser.
    optimizer (torch.optim): Optimizer utilis√© pour l'optimisation.
    epoch (int): Num√©ro de l'epoch.
    dataloader (Dataloader): Dataloader des donn√©es d'entra√Ænement.

  Returns:
    koopmanModel (SimpleKoopmanNeuralNetwork): Trained model. Also saved in a "trainedModel.pt" file.
  
  \"""
  
  koopmanModel.train()
  epLoss = 0
  size = len(dataloader)

  for target in dataloader:

    optimizer.zero_grad()

    initialState, trueTrajectory = target[0], target  

    predictedTrajectory = koopmanModel(initialState)

    loss = koopmanLoss(trueTrajectory, predictedTrajectory)

    epLoss += loss.item()

    loss.backward()
    optimizer.step()

  print(f'Epoch {epoch}, loss = {epLoss/size}')

  return koopmanModel
        

""")
        
        st.markdown("Il suffit alors de boucler sur le nombre d'epochs d'entra√Ænement pour construire un mod√®le optimis√©.")